{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.utils import io\n",
    "#Adjust directories to own paths\n",
    "current_dir = os.path.dirname(r\"C:\\Users\\JNoot\\Documents\\University\\Bachelor Thesis\\New Code\\forecasting\\forecasts\")\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "sys.path.insert(0, parent_dir)\n",
    "sys.path.append(os.path.dirname(os.path.abspath(r\"C:\\Users\\JNoot\\Documents\\University\\Bachelor Thesis\\New Code\\forecasting\\forecasts\\perform_forecasts.ipynb\")) + '/..')\n",
    "\n",
    "\n",
    "from forecasting.data_preprocessing.obtain_data import obtainData\n",
    "from forecasting.forecasts.in_sample_forecasts import in_sample_forecast\n",
    "from forecasting.forecasts.out_of_sample_forecasts import forecast\n",
    "from forecasting.utils.squared_errors import get_errors\n",
    "from forecasting.utils.qlike import get_qlike\n",
    "from forecasting.utils.model_confidence_set import update_mcs_count\n",
    "from forecasting.utils.market_cycles import define_market_phases, cycle_errors, segment_data_by_phases, perform_kruskal, perform_dunn_test\n",
    "from forecasting.utils.large_mid_cap import get_grouped_errors, initialize_errors, collect_errors, compute_statistics\n",
    "from forecasting.utils.utility_benefits import expected_utility\n",
    "from scipy.stats import skew\n",
    "from tqdm import notebook\n",
    "\n",
    "\n",
    "def perform_models(coins, in_sample, training_size=0.7):\n",
    "    results = {\n",
    "        'coin': [],\n",
    "        'LLF_rmse': [], 'RF_rmse': [], 'GARCH_rmse': [], 'GJR_rmse': [], 'HAR-RV_rmse': [],\n",
    "        'LLF_mae': [], 'RF_mae': [], 'GARCH_mae': [], 'GJR_mae': [], 'HAR-RV_mae': [],\n",
    "        'LLF_qlike': [], 'RF_qlike': [], 'GARCH_qlike': [], 'GJR_qlike': [], 'HAR-RV_qlike': [],\n",
    "        'LLF_utility': [], 'RF_utility': [], 'GARCH_utility': [], 'GJR_utility': [], 'HAR-RV_utility': []\n",
    "    }\n",
    "\n",
    "    mcs_counts_rmse = {model: 0 for model in ['LLF', 'RF', 'GARCH', 'GJR', 'HAR-RV']}\n",
    "    mcs_counts_qlike = {model: 0 for model in ['LLF', 'RF', 'GARCH', 'GJR', 'HAR-RV']}\n",
    "    mcs_counts_utility = {model: 0 for model in ['LLF', 'RF', 'GARCH', 'GJR', 'HAR-RV']}\n",
    "    mcs_counts_mae = {model: 0 for model in ['LLF', 'RF', 'GARCH', 'GJR', 'HAR-RV']}\n",
    "    mcsr_rmse = {}\n",
    "    mcsr_qlike = {}\n",
    "    mcsr_utility = {}\n",
    "    mcsr_mae = {}\n",
    "\n",
    "    phase_mcs_counts_rmse = {\n",
    "        'bull': {model: 0 for model in ['LLF', 'RF', 'GARCH', 'GJR', 'HAR-RV']},\n",
    "        'bear': {model: 0 for model in ['LLF', 'RF', 'GARCH', 'GJR', 'HAR-RV']},\n",
    "        'consolidating': {model: 0 for model in ['LLF', 'RF', 'GARCH', 'GJR', 'HAR-RV']}\n",
    "    }\n",
    "    phase_mcsr_rmse = {\n",
    "        'bull': {model: 0 for model in ['LLF', 'RF', 'GARCH', 'GJR', 'HAR-RV']},\n",
    "        'bear': {model: 0 for model in ['LLF', 'RF', 'GARCH', 'GJR', 'HAR-RV']},\n",
    "        'consolidating': {model: 0 for model in ['LLF', 'RF', 'GARCH', 'GJR', 'HAR-RV']}\n",
    "    }\n",
    "\n",
    "    # Large vs. Mid cap.\n",
    "    large_cap_coins = [\"Bitcoin\", \"Ethereum\", \"Tether\", \"Binance Coin\"]\n",
    "    mid_cap_coins = [\"Bitcoin Cash\", \"Litecoin\", \"Internet Computer\", \"Polygon\"]\n",
    "    large_cap_errors = initialize_errors()\n",
    "    mid_cap_errors = initialize_errors()\n",
    "\n",
    "    for coin in notebook.tqdm(coins):\n",
    "        print(coin)\n",
    "        with io.capture_output() as captured:\n",
    "            X, Y, X_ridge = obtainData(coin)\n",
    "        if in_sample:\n",
    "            predictions, Y_test = in_sample_forecast(X, Y, X_ridge)\n",
    "        else:\n",
    "            predictions, Y_test = forecast(coin, X, Y, X_ridge, training_size)\n",
    "        \n",
    "        mse, mae, rmse = get_errors(predictions, Y_test)\n",
    "        qlike = get_qlike(predictions, Y_test)\n",
    "        utility = expected_utility(predictions, Y_test)\n",
    "\n",
    "        results['coin'].append(coin)\n",
    "        for metric, res_dict in zip(['rmse', 'mae', 'qlike', 'utility'], [rmse, mae, qlike, utility]):\n",
    "            for model in ['LLF', 'RF', 'GARCH', 'GJR', 'HAR-RV']:\n",
    "                results[f'{model}_{metric}'].append(res_dict[model])\n",
    "\n",
    "        mcs_counts_rmse, mcs_counts_mae, mcs_counts_qlike, mcs_counts_utility, _ = update_mcs_count(\n",
    "            predictions, Y_test, mcs_counts_rmse=mcs_counts_rmse,  mcs_counts_mae= mcs_counts_mae, mcs_counts_qlike=mcs_counts_qlike, mcs_counts_utility=mcs_counts_utility\n",
    "        )\n",
    "\n",
    "        large_cap_errors, mid_cap_errors = collect_errors(predictions, Y_test, coin, large_cap_coins, mid_cap_coins, large_cap_errors, mid_cap_errors)\n",
    "\n",
    "        print('rmse', rmse)\n",
    "        print('qlike', qlike)\n",
    "        print('counts', mcs_counts_rmse, mcs_counts_mae, mcs_counts_qlike, mcs_counts_utility)\n",
    "        \n",
    "        if not in_sample:\n",
    "            # Define market phases\n",
    "            market_phases = define_market_phases(X['Close'])\n",
    "            total_errors = cycle_errors(predictions, Y_test)\n",
    "            errors_by_phase, phase_counts = segment_data_by_phases(total_errors, market_phases)\n",
    "\n",
    "            print(\"Number of observations in each phase:\")\n",
    "            for phase, count in phase_counts.items():\n",
    "                print(f\"{phase}: {count}\")\n",
    "\n",
    "            if coin != 'Tether':\n",
    "                for phase in ['bull', 'bear', 'consolidating']:\n",
    "                    _,_,_,_, phase_mcs_counts_rmse[phase] = update_mcs_count(total_errors, Y_test, mcs_counts_phase= phase_mcs_counts_rmse[phase])\n",
    "\n",
    "                # Perform Kruskal-Wallis and Dunn's tests\n",
    "                kruskal_results = perform_kruskal(errors_by_phase)\n",
    "                dunn_results = perform_dunn_test(errors_by_phase)\n",
    "\n",
    "                # Print statistics, Kruskal-Wallis results, and Dunn's test results for each model\n",
    "                for model, phase_data in errors_by_phase.items():\n",
    "                    print(f\"Statistics for model {model} on coin {coin}:\")\n",
    "                    for phase, errors in phase_data.items():\n",
    "                        errors_array = np.array(errors)\n",
    "                        print(f\"{phase}:\")\n",
    "                        print(f\"  Mean: {np.mean(errors_array)}\")\n",
    "                        print(f\"  Standard Deviation: {np.std(errors_array)}\")\n",
    "                        print(f\"  Skewness: {skew(errors_array)}\")\n",
    "\n",
    "                    # Print Kruskal-Wallis results\n",
    "                    kruskal_result = kruskal_results[model]\n",
    "                    print(f\"\\nKruskal-Wallis results for model {model} on coin {coin}:\")\n",
    "                    print(f\"Statistic = {kruskal_result['stat']}, p-value = {kruskal_result['p_value']}\")\n",
    "\n",
    "                    # Print Dunn's test results\n",
    "                    dunn_result = dunn_results[model]\n",
    "                    print(f\"\\nDunn's test results for model {model} on coin {coin} (p-values):\")\n",
    "                    print(dunn_result)\n",
    "    \n",
    "    # Calculate MCSR\n",
    "    for model in predictions.keys():\n",
    "        mcsr_rmse[model] = mcs_counts_rmse[model] / len(coins)\n",
    "        mcsr_mae[model] = mcs_counts_mae[model] / len(coins)\n",
    "        mcsr_qlike[model] = mcs_counts_qlike[model] / len(coins)\n",
    "        mcsr_utility[model] = mcs_counts_utility[model] / len(coins)\n",
    "\n",
    "    # Calculate MCSR by phase\n",
    "    for phase in ['bull', 'bear', 'consolidating']:\n",
    "        for model in predictions.keys():\n",
    "            phase_mcsr_rmse[phase][model] = phase_mcs_counts_rmse[phase][model] / (len(coins)-1) \n",
    "\n",
    "    combined_phase_mcsr_rmse = pd.DataFrame({\n",
    "        phase: phase_mcsr_rmse[phase] for phase in ['bull', 'bear', 'consolidating']\n",
    "    }).transpose()   \n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    large_cap_statistics = compute_statistics(large_cap_errors)\n",
    "    mid_cap_statistics = compute_statistics(mid_cap_errors)\n",
    "\n",
    "    print(\"Large Cap Errors:\")\n",
    "    print(large_cap_statistics)\n",
    "    print(\"\\nMid Cap Errors:\")\n",
    "    print(mid_cap_statistics)\n",
    "\n",
    "    # Generate and print LaTeX tables\n",
    "    latex_tables = {\n",
    "        'RMSE': results_df[['coin', 'LLF_rmse', 'RF_rmse', 'GARCH_rmse', 'GJR_rmse', 'HAR-RV_rmse']].to_latex(index=False, float_format=\"%.3f\"),\n",
    "        'MAE': results_df[['coin', 'LLF_mae', 'RF_mae', 'GARCH_mae', 'GJR_mae', 'HAR-RV_mae']].to_latex(index=False, float_format=\"%.3f\"),\n",
    "        'QLIKE': results_df[['coin', 'LLF_qlike', 'RF_qlike', 'GARCH_qlike', 'GJR_qlike', 'HAR-RV_qlike']].to_latex(index=False, float_format=\"%.3f\"),\n",
    "        'Utility': results_df[['coin', 'LLF_utility', 'RF_utility', 'GARCH_utility', 'GJR_utility', 'HAR-RV_utility']].to_latex(index=False, float_format=\"%.3f\"),\n",
    "        'MCSR': pd.DataFrame([mcsr_rmse, mcsr_mae, mcsr_qlike, mcsr_utility], index=['RMSE', 'MAE', 'QLIKE', 'Utility']).to_latex(float_format=\"%.3f\"),\n",
    "        'MCSR_Phases' : combined_phase_mcsr_rmse.to_latex(float_format=\"%.3f\", index=True)\n",
    "    }\n",
    "    \n",
    "    #Save tables to results\n",
    "    current_dir = os.getcwd()\n",
    "    tables_dir = os.path.join(current_dir, \"..\", \"Results\", \"tables\")\n",
    "\n",
    "    for name, table in latex_tables.items():\n",
    "        feature = name.lower()\n",
    "        if in_sample:\n",
    "            save_path = os.path.join(tables_dir, f\"{feature}_in_sample.tex\")\n",
    "        else:\n",
    "            save_path = os.path.join(tables_dir, f\"{feature}_out-of_sample.tex\")\n",
    "        with open(save_path, 'w') as f:\n",
    "            f.write(table)\n",
    "\n",
    "    return latex_tables\n",
    "\n",
    "coins = [\"Bitcoin\", \"Ethereum\", \"Tether\", \"Binance Coin\", \"Bitcoin Cash\", \"Litecoin\", \"Internet Computer\", \"Polygon\"]\n",
    "\n",
    "#In-sample Forecasts\n",
    "latex_tables_in_sample = perform_models(coins, in_sample=True)\n",
    "for name, table in latex_tables_in_sample.items():\n",
    "    print(f\"{name} Table:\")\n",
    "    print(table)\n",
    "\n",
    "# Out-of-Sample Forecasts\n",
    "latex_tables_out_sample = perform_models(coins, in_sample=False, training_size=0.90)\n",
    "for name, table in latex_tables_out_sample.items():\n",
    "    print(f\"{name} Table:\")\n",
    "    print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
