{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f528f2ad46444ba85262cfc528c24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitcoin\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 120\u001b[0m\n\u001b[0;32m    117\u001b[0m coins \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBitcoin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEthereum\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTether\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBinance Coin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBitcoin Cash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLitecoin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInternet Computer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolygon\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# In-sample Forecasts\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m latex_tables_in_sample \u001b[38;5;241m=\u001b[39m \u001b[43mperform_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, table \u001b[38;5;129;01min\u001b[39;00m latex_tables_in_sample\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Table:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 41\u001b[0m, in \u001b[0;36mperform_models\u001b[1;34m(coins, in_sample, training_size)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(coin)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m io\u001b[38;5;241m.\u001b[39mcapture_output() \u001b[38;5;28;01mas\u001b[39;00m captured:\n\u001b[1;32m---> 41\u001b[0m     X, Y, X_ridge \u001b[38;5;241m=\u001b[39m \u001b[43mobtainData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_sample:\n\u001b[0;32m     43\u001b[0m     predictions, Y_test \u001b[38;5;241m=\u001b[39m in_sample_forecast(X, Y, X_ridge)\n",
      "File \u001b[1;32m~\\Documents\\University\\Bachelor Thesis\\New Code\\forecasting\\data_p\\obtain_data.py:186\u001b[0m, in \u001b[0;36mobtainData\u001b[1;34m(coin)\u001b[0m\n\u001b[0;32m    183\u001b[0m initial_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHigh\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLow\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolume eur\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    184\u001b[0m ridge_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39minitial_features)\n\u001b[1;32m--> 186\u001b[0m stationary_data, differencing \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_non_stationarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mridge_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m##Subtract 22 days for the HAR-RV model\u001b[39;00m\n\u001b[0;32m    188\u001b[0m start_time \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021-08-01\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m dt\u001b[38;5;241m.\u001b[39mtimedelta(days \u001b[38;5;241m=\u001b[39m differencing) \u001b[38;5;241m-\u001b[39m dt\u001b[38;5;241m.\u001b[39mtimedelta(days \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m22\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\University\\Bachelor Thesis\\New Code\\forecasting\\data_p\\obtain_data.py:38\u001b[0m, in \u001b[0;36mhandle_non_stationarity\u001b[1;34m(feature_set)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandle_non_stationarity\u001b[39m(feature_set):\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# Test for stationarity\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m     non_stationary_features \u001b[38;5;241m=\u001b[39m \u001b[43mtest_stationarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     differencing \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# Take differences until all features are stationary\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\University\\Bachelor Thesis\\New Code\\forecasting\\data_p\\obtain_data.py:26\u001b[0m, in \u001b[0;36mtest_stationarity\u001b[1;34m(feature_set)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m feature_set\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Perform Augmented Dickey-Fuller test\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_set[column]\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m!=\u001b[39m feature_set[column]\u001b[38;5;241m.\u001b[39mmax():\n\u001b[1;32m---> 26\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43madfuller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m         p_value \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;66;03m# Check the p-value\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JNoot\\Documents\\University\\Bachelor Thesis\\New Code\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\stattools.py:326\u001b[0m, in \u001b[0;36madfuller\u001b[1;34m(x, maxlag, regression, autolag, store, regresults)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;66;03m# 1 for level\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# search for lag length with smallest information criteria\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;66;03m# Note: use the same number of observations to have comparable IC\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# aic and bic: smaller is better\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m regresults:\n\u001b[1;32m--> 326\u001b[0m     icbest, bestlag \u001b[38;5;241m=\u001b[39m \u001b[43m_autolag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mOLS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxdshort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfullRHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstartlag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautolag\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     icbest, bestlag, alres \u001b[38;5;241m=\u001b[39m _autolag(\n\u001b[0;32m    331\u001b[0m         OLS,\n\u001b[0;32m    332\u001b[0m         xdshort,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    337\u001b[0m         regresults\u001b[38;5;241m=\u001b[39mregresults,\n\u001b[0;32m    338\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\JNoot\\Documents\\University\\Bachelor Thesis\\New Code\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\stattools.py:133\u001b[0m, in \u001b[0;36m_autolag\u001b[1;34m(mod, endog, exog, startlag, maxlag, method, modargs, fitargs, regresults)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(startlag, startlag \u001b[38;5;241m+\u001b[39m maxlag \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    132\u001b[0m     mod_instance \u001b[38;5;241m=\u001b[39m mod(endog, exog[:, :lag], \u001b[38;5;241m*\u001b[39mmodargs)\n\u001b[1;32m--> 133\u001b[0m     results[lag] \u001b[38;5;241m=\u001b[39m \u001b[43mmod_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maic\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    136\u001b[0m     icbest, bestlag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m((v\u001b[38;5;241m.\u001b[39maic, k) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems())\n",
      "File \u001b[1;32mc:\\Users\\JNoot\\Documents\\University\\Bachelor Thesis\\New Code\\.venv\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:336\u001b[0m, in \u001b[0;36mRegressionModel.fit\u001b[1;34m(self, method, cov_type, cov_kwds, use_t, **kwargs)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpinv\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpinv_wexog\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    333\u001b[0m             \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_cov_params\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    334\u001b[0m             \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m--> 336\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog, singular_values \u001b[38;5;241m=\u001b[39m \u001b[43mpinv_extended\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwexog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalized_cov_params \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\n\u001b[0;32m    338\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog, np\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog))\n\u001b[0;32m    340\u001b[0m         \u001b[38;5;66;03m# Cache these singular values for use later.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JNoot\\Documents\\University\\Bachelor Thesis\\New Code\\.venv\\Lib\\site-packages\\statsmodels\\tools\\tools.py:264\u001b[0m, in \u001b[0;36mpinv_extended\u001b[1;34m(x, rcond)\u001b[0m\n\u001b[0;32m    262\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\n\u001b[0;32m    263\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mconjugate()\n\u001b[1;32m--> 264\u001b[0m u, s, vt \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    265\u001b[0m s_orig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(s)\n\u001b[0;32m    266\u001b[0m m \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\JNoot\\Documents\\University\\Bachelor Thesis\\New Code\\.venv\\Lib\\site-packages\\numpy\\linalg\\linalg.py:1681\u001b[0m, in \u001b[0;36msvd\u001b[1;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[0;32m   1678\u001b[0m         gufunc \u001b[38;5;241m=\u001b[39m _umath_linalg\u001b[38;5;241m.\u001b[39msvd_n_s\n\u001b[0;32m   1680\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->DdD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->ddd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1681\u001b[0m u, s, vh \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1682\u001b[0m u \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1683\u001b[0m s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mastype(_realType(result_t), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.utils import io\n",
    "current_dir = os.path.dirname(r\"C:\\Users\\JNoot\\Documents\\University\\Bachelor Thesis\\New Code\\forecasting\\forecasts\")\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "sys.path.insert(0, parent_dir)\n",
    "sys.path.append(os.path.dirname(os.path.abspath(r\"C:\\Users\\JNoot\\Documents\\University\\Bachelor Thesis\\New Code\\forecasting\\forecasts\\perform_forecasts.ipynb\")) + '/..')\n",
    "\n",
    "from forecasting.data_preprocessing.obtain_data import obtainData\n",
    "from forecasting.forecasts.in_sample_forecasts import in_sample_forecast\n",
    "from forecasting.forecasts.out_of_sample_forecasts import forecast\n",
    "from forecasting.utils.squared_errors import get_errors\n",
    "from forecasting.utils.qlike import get_qlike\n",
    "from forecasting.utils.model_confidence_set import update_mcs_count\n",
    "from forecasting.utils.market_cycles import define_market_phases, cycle_errors, segment_data_by_phases, perform_kruskal, perform_dunn_test\n",
    "from scipy.stats import skew\n",
    "from tqdm import notebook\n",
    "\n",
    "\n",
    "def perform_models(coins, in_sample, training_size=0.7):\n",
    "    results = {\n",
    "        'coin': [],\n",
    "        'LLF_rmse': [], 'RF_rmse': [], 'GARCH_rmse': [], 'GJR_rmse': [], 'HAR-RV_rmse': [],\n",
    "        'LLF_mae': [], 'RF_mae': [], 'GARCH_mae': [], 'GJR_mae': [], 'HAR-RV_mae': [],\n",
    "        'LLF_qlike': [], 'RF_qlike': [], 'GARCH_qlike': [], 'GJR_qlike': [], 'HAR-RV_qlike': []\n",
    "    }\n",
    "\n",
    "    mcs_counts_rmse = {model: 0 for model in ['LLF', 'RF', 'GARCH', 'GJR', 'HAR-RV']}\n",
    "    mcs_counts_qlike = {model: 0 for model in ['LLF', 'RF', 'GARCH', 'GJR', 'HAR-RV']}\n",
    "    mcs_counts_utility = {model: 0 for model in ['LLF', 'RF', 'GARCH', 'GJR', 'HAR-RV']}\n",
    "    mcsr_rmse = {}\n",
    "    mcsr_qlike = {}\n",
    "    mcsr_utility = {}\n",
    "\n",
    "    for coin in notebook.tqdm(coins):\n",
    "        print(coin)\n",
    "        with io.capture_output() as captured:\n",
    "            X, Y, X_ridge = obtainData(coin)\n",
    "        if in_sample:\n",
    "            predictions, Y_test = in_sample_forecast(X, Y, X_ridge)\n",
    "        else:\n",
    "            predictions, Y_test = forecast(X, Y, X_ridge, training_size)\n",
    "        \n",
    "        mse, mae, rmse = get_errors(predictions, Y_test)\n",
    "        qlike = get_qlike(predictions, Y_test)\n",
    "\n",
    "        results['coin'].append(coin)\n",
    "        for metric, res_dict in zip(['rmse', 'mae', 'qlike'], [rmse, mae, qlike]):\n",
    "            for model in ['LLF', 'RF', 'GARCH', 'GJR', 'HAR-RV']:\n",
    "                results[f'{model}_{metric}'].append(res_dict[model])\n",
    "\n",
    "        mcs_counts_rmse, mcs_counts_qlike, mcs_counts_utility = update_mcs_count(\n",
    "            predictions, Y_test, mcs_counts_rmse=mcs_counts_rmse, mcs_counts_qlike=mcs_counts_qlike, mcs_counts_utility=mcs_counts_utility\n",
    "        )\n",
    "\n",
    "        print('rmse', rmse)\n",
    "        print('qlike', qlike)\n",
    "        print('counts', mcs_counts_rmse, mcs_counts_qlike, mcs_counts_utility)\n",
    "        \n",
    "        if not in_sample:\n",
    "            # Define market phases\n",
    "            market_phases = define_market_phases(X['Close'])\n",
    "            total_errors = cycle_errors(predictions, Y_test)\n",
    "            errors_by_phase, phase_counts = segment_data_by_phases(total_errors, market_phases)\n",
    "\n",
    "            # Print the number of observations in each phase\n",
    "            print(\"Number of observations in each phase:\")\n",
    "            for phase, count in phase_counts.items():\n",
    "                print(f\"{phase}: {count}\")\n",
    "\n",
    "            if coin != 'Tether':\n",
    "                # Perform Kruskal-Wallis and Dunn's tests\n",
    "                kruskal_results = perform_kruskal(errors_by_phase)\n",
    "                dunn_results = perform_dunn_test(errors_by_phase)\n",
    "\n",
    "                # Print statistics, Kruskal-Wallis results, and Dunn's test results for each model\n",
    "                for model, phase_data in errors_by_phase.items():\n",
    "                    print(f\"Statistics for model {model} on coin {coin}:\")\n",
    "                    for phase, errors in phase_data.items():\n",
    "                        errors_array = np.array(errors)\n",
    "                        print(f\"{phase}:\")\n",
    "                        print(f\"  Mean: {np.mean(errors_array)}\")\n",
    "                        print(f\"  Standard Deviation: {np.std(errors_array)}\")\n",
    "                        print(f\"  Skewness: {skew(errors_array)}\")\n",
    "\n",
    "                    # Print Kruskal-Wallis results\n",
    "                    kruskal_result = kruskal_results[model]\n",
    "                    print(f\"\\nKruskal-Wallis results for model {model} on coin {coin}:\")\n",
    "                    print(f\"Statistic = {kruskal_result['stat']}, p-value = {kruskal_result['p_value']}\")\n",
    "\n",
    "                    # Print Dunn's test results\n",
    "                    dunn_result = dunn_results[model]\n",
    "                    print(f\"\\nDunn's test results for model {model} on coin {coin} (p-values):\")\n",
    "                    print(dunn_result)\n",
    "    \n",
    "    # Calculate MCSR\n",
    "    for model in predictions.keys():\n",
    "        mcsr_rmse[model] = mcs_counts_rmse[model] / len(coins)\n",
    "        mcsr_qlike[model] = mcs_counts_qlike[model] / len(coins)\n",
    "        mcsr_utility[model] = mcs_counts_utility[model] / len(coins)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Generate and print LaTeX tables\n",
    "    latex_tables = {\n",
    "        'RMSE': results_df[['coin', 'LLF_rmse', 'RF_rmse', 'GARCH_rmse', 'GJR_rmse', 'HAR-RV_rmse']].to_latex(index=False, float_format=\"%.3f\"),\n",
    "        'MAE': results_df[['coin', 'LLF_mae', 'RF_mae', 'GARCH_mae', 'GJR_mae', 'HAR-RV_mae']].to_latex(index=False, float_format=\"%.3f\"),\n",
    "        'QLIKE': results_df[['coin', 'LLF_qlike', 'RF_qlike', 'GARCH_qlike', 'GJR_qlike', 'HAR-RV_qlike']].to_latex(index=False, float_format=\"%.3f\"),\n",
    "        'MCS Counts': pd.DataFrame([mcsr_rmse, mcsr_qlike, mcsr_utility], index=['RMSE', 'QLIKE', 'Utility']).to_latex(float_format=\"%.3f\")\n",
    "    }\n",
    "    \n",
    "    return latex_tables\n",
    "\n",
    "coins = [\"Bitcoin\", \"Ethereum\", \"Tether\", \"Binance Coin\", \"Bitcoin Cash\", \"Litecoin\", \"Internet Computer\", \"Polygon\"]\n",
    "\n",
    "# In-sample Forecasts\n",
    "latex_tables_in_sample = perform_models(coins, in_sample=True)\n",
    "for name, table in latex_tables_in_sample.items():\n",
    "    print(f\"{name} Table:\")\n",
    "    print(table)\n",
    "\n",
    "# Out-of-Sample Forecasts\n",
    "latex_tables_out_sample = perform_models(coins, in_sample=False, training_size=0.70)\n",
    "for name, table in latex_tables_out_sample.items():\n",
    "    print(f\"{name} Table:\")\n",
    "    print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
