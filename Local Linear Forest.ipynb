{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting econml\n",
      "  Using cached econml-0.15.0-cp312-cp312-win_amd64.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\jnoot\\documents\\university\\bachelor thesis\\new code\\.venv\\lib\\site-packages (from econml) (1.26.4)\n",
      "Requirement already satisfied: scipy>1.4.0 in c:\\users\\jnoot\\documents\\university\\bachelor thesis\\new code\\.venv\\lib\\site-packages (from econml) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn<1.5,>=1.0 in c:\\users\\jnoot\\documents\\university\\bachelor thesis\\new code\\.venv\\lib\\site-packages (from econml) (1.4.2)\n",
      "Collecting sparse (from econml)\n",
      "  Using cached sparse-0.15.2-py2.py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: joblib>=0.13.0 in c:\\users\\jnoot\\documents\\university\\bachelor thesis\\new code\\.venv\\lib\\site-packages (from econml) (1.4.2)\n",
      "Collecting statsmodels>=0.10 (from econml)\n",
      "  Using cached statsmodels-0.14.2-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: pandas>1.0 in c:\\users\\jnoot\\documents\\university\\bachelor thesis\\new code\\.venv\\lib\\site-packages (from econml) (2.2.2)\n",
      "Collecting shap<0.44.0,>=0.38.1 (from econml)\n",
      "  Using cached shap-0.43.0.tar.gz (389 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting lightgbm (from econml)\n",
      "  Using cached lightgbm-4.3.0-py3-none-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jnoot\\documents\\university\\bachelor thesis\\new code\\.venv\\lib\\site-packages (from pandas>1.0->econml) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jnoot\\documents\\university\\bachelor thesis\\new code\\.venv\\lib\\site-packages (from pandas>1.0->econml) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jnoot\\documents\\university\\bachelor thesis\\new code\\.venv\\lib\\site-packages (from pandas>1.0->econml) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jnoot\\documents\\university\\bachelor thesis\\new code\\.venv\\lib\\site-packages (from scikit-learn<1.5,>=1.0->econml) (3.5.0)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\jnoot\\documents\\university\\bachelor thesis\\new code\\.venv\\lib\\site-packages (from shap<0.44.0,>=0.38.1->econml) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\jnoot\\documents\\university\\bachelor thesis\\new code\\.venv\\lib\\site-packages (from shap<0.44.0,>=0.38.1->econml) (24.0)\n",
      "Collecting slicer==0.0.7 (from shap<0.44.0,>=0.38.1->econml)\n",
      "  Using cached slicer-0.0.7-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting numba (from shap<0.44.0,>=0.38.1->econml)\n",
      "  Using cached numba-0.59.1-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting cloudpickle (from shap<0.44.0,>=0.38.1->econml)\n",
      "  Using cached cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting patsy>=0.5.6 (from statsmodels>=0.10->econml)\n",
      "  Using cached patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba->shap<0.44.0,>=0.38.1->econml)\n",
      "  Using cached llvmlite-0.42.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: six in c:\\users\\jnoot\\documents\\university\\bachelor thesis\\new code\\.venv\\lib\\site-packages (from patsy>=0.5.6->statsmodels>=0.10->econml) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jnoot\\documents\\university\\bachelor thesis\\new code\\.venv\\lib\\site-packages (from tqdm>=4.27.0->shap<0.44.0,>=0.38.1->econml) (0.4.6)\n",
      "Using cached econml-0.15.0-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Using cached statsmodels-0.14.2-cp312-cp312-win_amd64.whl (9.8 MB)\n",
      "Using cached lightgbm-4.3.0-py3-none-win_amd64.whl (1.3 MB)\n",
      "Using cached sparse-0.15.2-py2.py3-none-any.whl (116 kB)\n",
      "Using cached numba-0.59.1-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "Using cached patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "Using cached cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Using cached llvmlite-0.42.0-cp312-cp312-win_amd64.whl (28.1 MB)\n",
      "Building wheels for collected packages: shap\n",
      "  Building wheel for shap (pyproject.toml): started\n",
      "  Building wheel for shap (pyproject.toml): finished with status 'error'\n",
      "Failed to build shap\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for shap (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [171 lines of output]\n",
      "      The nvcc binary could not be located in your $PATH. Either add it to your path, or set $CUDAHOME to enable CUDA.\n",
      "      Exception occurred during setup, Error building cuda module: TypeError('cannot unpack non-iterable NoneType object')\n",
      "      WARNING: Could not compile cuda extensions.\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build\\lib.win-amd64-cpython-312\n",
      "      creating build\\lib.win-amd64-cpython-312\\shap\n",
      "      copying shap\\datasets.py -> build\\lib.win-amd64-cpython-312\\shap\n",
      "      copying shap\\links.py -> build\\lib.win-amd64-cpython-312\\shap\n",
      "      copying shap\\_explanation.py -> build\\lib.win-amd64-cpython-312\\shap\n",
      "      copying shap\\_serializable.py -> build\\lib.win-amd64-cpython-312\\shap\n",
      "      copying shap\\__init__.py -> build\\lib.win-amd64-cpython-312\\shap\n",
      "      creating build\\lib.win-amd64-cpython-312\\shap\\explainers\n",
      "      copying shap\\explainers\\pytree.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\n",
      "      copying shap\\explainers\\tf_utils.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\n",
      "      copying shap\\explainers\\_additive.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\n",
      "      copying shap\\explainers\\_exact.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\n",
      "      copying shap\\explainers\\_explainer.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\n",
      "      copying shap\\explainers\\_gpu_tree.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\n",
      "      copying shap\\explainers\\_gradient.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\n",
      "      copying shap\\explainers\\_kernel.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\n",
      "      copying shap\\explainers\\_linear.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\n",
      "      copying shap\\explainers\\_partition.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\n",
      "      copying shap\\explainers\\_permutation.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\n",
      "      copying shap\\explainers\\_sampling.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\n",
      "      copying shap\\explainers\\_tree.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\n",
      "      copying shap\\explainers\\__init__.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\n",
      "      creating build\\lib.win-amd64-cpython-312\\shap\\explainers\\other\n",
      "      copying shap\\explainers\\other\\_coefficient.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\\other\n",
      "      copying shap\\explainers\\other\\_lime.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\\other\n",
      "      copying shap\\explainers\\other\\_maple.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\\other\n",
      "      copying shap\\explainers\\other\\_random.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\\other\n",
      "      copying shap\\explainers\\other\\_treegain.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\\other\n",
      "      copying shap\\explainers\\other\\__init__.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\\other\n",
      "      creating build\\lib.win-amd64-cpython-312\\shap\\explainers\\_deep\n",
      "      copying shap\\explainers\\_deep\\deep_pytorch.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\\_deep\n",
      "      copying shap\\explainers\\_deep\\deep_tf.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\\_deep\n",
      "      copying shap\\explainers\\_deep\\deep_utils.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\\_deep\n",
      "      copying shap\\explainers\\_deep\\__init__.py -> build\\lib.win-amd64-cpython-312\\shap\\explainers\\_deep\n",
      "      creating build\\lib.win-amd64-cpython-312\\shap\\plots\n",
      "      copying shap\\plots\\_bar.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\n",
      "      copying shap\\plots\\_beeswarm.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\n",
      "      copying shap\\plots\\_benchmark.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\n",
      "      copying shap\\plots\\_decision.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\n",
      "      copying shap\\plots\\_embedding.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\n",
      "      copying shap\\plots\\_force.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\n",
      "      copying shap\\plots\\_force_matplotlib.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\n",
      "      copying shap\\plots\\_group_difference.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\n",
      "      copying shap\\plots\\_heatmap.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\n",
      "      copying shap\\plots\\_image.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\n",
      "      copying shap\\plots\\_labels.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\n",
      "      copying shap\\plots\\_monitoring.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\n",
      "      copying shap\\plots\\_partial_dependence.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\n",
      "      copying shap\\plots\\_scatter.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\n",
      "      copying shap\\plots\\_text.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\n",
      "      copying shap\\plots\\_utils.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\n",
      "      copying shap\\plots\\_violin.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\n",
      "      copying shap\\plots\\_waterfall.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\n",
      "      copying shap\\plots\\__init__.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\n",
      "      creating build\\lib.win-amd64-cpython-312\\shap\\plots\\colors\n",
      "      copying shap\\plots\\colors\\_colorconv.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\\colors\n",
      "      copying shap\\plots\\colors\\_colors.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\\colors\n",
      "      copying shap\\plots\\colors\\__init__.py -> build\\lib.win-amd64-cpython-312\\shap\\plots\\colors\n",
      "      creating build\\lib.win-amd64-cpython-312\\shap\\benchmark\n",
      "      copying shap\\benchmark\\experiments.py -> build\\lib.win-amd64-cpython-312\\shap\\benchmark\n",
      "      copying shap\\benchmark\\framework.py -> build\\lib.win-amd64-cpython-312\\shap\\benchmark\n",
      "      copying shap\\benchmark\\measures.py -> build\\lib.win-amd64-cpython-312\\shap\\benchmark\n",
      "      copying shap\\benchmark\\methods.py -> build\\lib.win-amd64-cpython-312\\shap\\benchmark\n",
      "      copying shap\\benchmark\\metrics.py -> build\\lib.win-amd64-cpython-312\\shap\\benchmark\n",
      "      copying shap\\benchmark\\models.py -> build\\lib.win-amd64-cpython-312\\shap\\benchmark\n",
      "      copying shap\\benchmark\\plots.py -> build\\lib.win-amd64-cpython-312\\shap\\benchmark\n",
      "      copying shap\\benchmark\\_compute.py -> build\\lib.win-amd64-cpython-312\\shap\\benchmark\n",
      "      copying shap\\benchmark\\_explanation_error.py -> build\\lib.win-amd64-cpython-312\\shap\\benchmark\n",
      "      copying shap\\benchmark\\_result.py -> build\\lib.win-amd64-cpython-312\\shap\\benchmark\n",
      "      copying shap\\benchmark\\_sequential.py -> build\\lib.win-amd64-cpython-312\\shap\\benchmark\n",
      "      copying shap\\benchmark\\__init__.py -> build\\lib.win-amd64-cpython-312\\shap\\benchmark\n",
      "      creating build\\lib.win-amd64-cpython-312\\shap\\maskers\n",
      "      copying shap\\maskers\\_composite.py -> build\\lib.win-amd64-cpython-312\\shap\\maskers\n",
      "      copying shap\\maskers\\_fixed.py -> build\\lib.win-amd64-cpython-312\\shap\\maskers\n",
      "      copying shap\\maskers\\_fixed_composite.py -> build\\lib.win-amd64-cpython-312\\shap\\maskers\n",
      "      copying shap\\maskers\\_image.py -> build\\lib.win-amd64-cpython-312\\shap\\maskers\n",
      "      copying shap\\maskers\\_masker.py -> build\\lib.win-amd64-cpython-312\\shap\\maskers\n",
      "      copying shap\\maskers\\_output_composite.py -> build\\lib.win-amd64-cpython-312\\shap\\maskers\n",
      "      copying shap\\maskers\\_tabular.py -> build\\lib.win-amd64-cpython-312\\shap\\maskers\n",
      "      copying shap\\maskers\\_text.py -> build\\lib.win-amd64-cpython-312\\shap\\maskers\n",
      "      copying shap\\maskers\\__init__.py -> build\\lib.win-amd64-cpython-312\\shap\\maskers\n",
      "      creating build\\lib.win-amd64-cpython-312\\shap\\utils\n",
      "      copying shap\\utils\\image.py -> build\\lib.win-amd64-cpython-312\\shap\\utils\n",
      "      copying shap\\utils\\transformers.py -> build\\lib.win-amd64-cpython-312\\shap\\utils\n",
      "      copying shap\\utils\\_clustering.py -> build\\lib.win-amd64-cpython-312\\shap\\utils\n",
      "      copying shap\\utils\\_exceptions.py -> build\\lib.win-amd64-cpython-312\\shap\\utils\n",
      "      copying shap\\utils\\_general.py -> build\\lib.win-amd64-cpython-312\\shap\\utils\n",
      "      copying shap\\utils\\_keras.py -> build\\lib.win-amd64-cpython-312\\shap\\utils\n",
      "      copying shap\\utils\\_legacy.py -> build\\lib.win-amd64-cpython-312\\shap\\utils\n",
      "      copying shap\\utils\\_masked_model.py -> build\\lib.win-amd64-cpython-312\\shap\\utils\n",
      "      copying shap\\utils\\_show_progress.py -> build\\lib.win-amd64-cpython-312\\shap\\utils\n",
      "      copying shap\\utils\\__init__.py -> build\\lib.win-amd64-cpython-312\\shap\\utils\n",
      "      creating build\\lib.win-amd64-cpython-312\\shap\\actions\n",
      "      copying shap\\actions\\_action.py -> build\\lib.win-amd64-cpython-312\\shap\\actions\n",
      "      copying shap\\actions\\_optimizer.py -> build\\lib.win-amd64-cpython-312\\shap\\actions\n",
      "      copying shap\\actions\\__init__.py -> build\\lib.win-amd64-cpython-312\\shap\\actions\n",
      "      creating build\\lib.win-amd64-cpython-312\\shap\\models\n",
      "      copying shap\\models\\_model.py -> build\\lib.win-amd64-cpython-312\\shap\\models\n",
      "      copying shap\\models\\_teacher_forcing.py -> build\\lib.win-amd64-cpython-312\\shap\\models\n",
      "      copying shap\\models\\_text_generation.py -> build\\lib.win-amd64-cpython-312\\shap\\models\n",
      "      copying shap\\models\\_topk_lm.py -> build\\lib.win-amd64-cpython-312\\shap\\models\n",
      "      copying shap\\models\\_transformers_pipeline.py -> build\\lib.win-amd64-cpython-312\\shap\\models\n",
      "      copying shap\\models\\__init__.py -> build\\lib.win-amd64-cpython-312\\shap\\models\n",
      "      running egg_info\n",
      "      writing shap.egg-info\\PKG-INFO\n",
      "      writing dependency_links to shap.egg-info\\dependency_links.txt\n",
      "      writing requirements to shap.egg-info\\requires.txt\n",
      "      writing top-level names to shap.egg-info\\top_level.txt\n",
      "      reading manifest file 'shap.egg-info\\SOURCES.txt'\n",
      "      adding license file 'LICENSE'\n",
      "      writing manifest file 'shap.egg-info\\SOURCES.txt'\n",
      "      C:\\Users\\JNoot\\AppData\\Local\\Temp\\pip-build-env-hiz9hxf2\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:207: _Warning: Package 'shap.cext' is absent from the `packages` configuration.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              ############################\n",
      "              # Package would be ignored #\n",
      "              ############################\n",
      "              Python recognizes 'shap.cext' as an importable package[^1],\n",
      "              but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "              This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "              package, please make sure that 'shap.cext' is explicitly added\n",
      "              to the `packages` configuration field.\n",
      "      \n",
      "              Alternatively, you can also rely on setuptools' discovery methods\n",
      "              (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "              instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "              You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "              If you don't want 'shap.cext' to be distributed and are\n",
      "              already explicitly excluding 'shap.cext' via\n",
      "              `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "              you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "              combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "              You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "              - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "              [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                    even if it does not contain any `.py` files.\n",
      "                    On the other hand, currently there is no concept of package data\n",
      "                    directory, all directories are treated like packages.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        check.warn(importable)\n",
      "      creating build\\lib.win-amd64-cpython-312\\shap\\cext\n",
      "      copying shap\\cext\\_cext.cc -> build\\lib.win-amd64-cpython-312\\shap\\cext\n",
      "      creating build\\lib.win-amd64-cpython-312\\shap\\plots\\resources\n",
      "      copying shap\\plots\\resources\\bundle.js -> build\\lib.win-amd64-cpython-312\\shap\\plots\\resources\n",
      "      copying shap\\plots\\resources\\logoSmallGray.png -> build\\lib.win-amd64-cpython-312\\shap\\plots\\resources\n",
      "      copying shap\\cext\\gpu_treeshap.h -> build\\lib.win-amd64-cpython-312\\shap\\cext\n",
      "      copying shap\\cext\\tree_shap.h -> build\\lib.win-amd64-cpython-312\\shap\\cext\n",
      "      copying shap\\cext\\_cext_gpu.cc -> build\\lib.win-amd64-cpython-312\\shap\\cext\n",
      "      copying shap\\cext\\_cext_gpu.cu -> build\\lib.win-amd64-cpython-312\\shap\\cext\n",
      "      running build_ext\n",
      "      building 'shap._cext' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for shap\n",
      "ERROR: Could not build wheels for shap, which is required to install pyproject.toml-based projects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\jnoot\\documents\\university\\bachelor thesis\\new code\\.venv\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\jnoot\\documents\\university\\bachelor thesis\\new code\\.venv\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\jnoot\\documents\\university\\bachelor thesis\\new code\\.venv\\lib\\site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jnoot\\documents\\university\\bachelor thesis\\new code\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jnoot\\documents\\university\\bachelor thesis\\new code\\.venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\jnoot\\documents\\university\\bachelor thesis\\new code\\.venv\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'econml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meconml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn_extensions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StatsModelsLinearRegression\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ridge\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'econml'"
     ]
    }
   ],
   "source": [
    "%pip install econml\n",
    "%pip install scikit-learn\n",
    "%pip install numpy\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from econml.sklearn_extensions.linear_model import StatsModelsLinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from typing import Optional\n",
    "\n",
    "def ll_regression_forest(X, Y, enable_ll_split=False, ll_split_weight_penalty=False,\n",
    "                         ll_split_lambda=0.1, ll_split_variables=None, ll_split_cutoff=None,\n",
    "                         num_trees=2000, clusters=None, equalize_cluster_weights=False,\n",
    "                         sample_fraction=0.5, mtry=None, min_node_size=5, honesty=True,\n",
    "                         honesty_fraction=0.5, honesty_prune_leaves=True, alpha=0.05,\n",
    "                         imbalance_penalty=0, ci_group_size=2, tune_parameters=\"none\",\n",
    "                         tune_num_trees=50, tune_num_reps=100, tune_num_draws=1000,\n",
    "                         num_threads=None, seed=None):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    if mtry is None:\n",
    "        mtry = min(int(np.sqrt(X.shape[1]) + 20), X.shape[1])\n",
    "\n",
    "    if ll_split_variables is None:\n",
    "        ll_split_variables = np.arange(X.shape[1])\n",
    "\n",
    "    if ll_split_cutoff is None:\n",
    "        ll_split_cutoff = int(np.sqrt(X.shape[0]))\n",
    "\n",
    "    def validate_num_threads(num_threads):\n",
    "        # Implement thread validation based on your environment\n",
    "        return num_threads\n",
    "\n",
    "    num_threads = validate_num_threads(num_threads)\n",
    "\n",
    "    # Train the random forest\n",
    "    rf = RandomForestRegressor(n_estimators=num_trees, max_features=mtry, min_samples_leaf=min_node_size,\n",
    "                               n_jobs=num_threads, random_state=seed)\n",
    "\n",
    "    rf.fit(X, Y)\n",
    "\n",
    "    if enable_ll_split and ll_split_cutoff > 0:\n",
    "        D = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "        J = np.eye(X.shape[1] + 1)\n",
    "        J[0, 0] = 0\n",
    "        overall_beta = np.linalg.inv(D.T @ D + ll_split_lambda * J) @ D.T @ Y\n",
    "    else:\n",
    "        overall_beta = None\n",
    "\n",
    "    # Create the local linear correction if enabled\n",
    "    if enable_ll_split:\n",
    "        if overall_beta is not None:\n",
    "            # Placeholder for more complex logic if needed\n",
    "            pass\n",
    "\n",
    "    # Return the trained forest and additional information\n",
    "    return {\n",
    "        \"forest\": rf,\n",
    "        \"overall_beta\": overall_beta,\n",
    "        \"params\": {\n",
    "            \"num_trees\": num_trees,\n",
    "            \"mtry\": mtry,\n",
    "            \"min_node_size\": min_node_size,\n",
    "            \"honesty\": honesty,\n",
    "            \"honesty_fraction\": honesty_fraction,\n",
    "            \"honesty_prune_leaves\": honesty_prune_leaves,\n",
    "            \"alpha\": alpha,\n",
    "            \"imbalance_penalty\": imbalance_penalty,\n",
    "            \"ci_group_size\": ci_group_size,\n",
    "            \"num_threads\": num_threads,\n",
    "            \"seed\": seed\n",
    "        }\n",
    "    }\n",
    "\n",
    "def predict_ll_regression_forest(forest_obj, newdata=None, linear_correction_variables=None,\n",
    "                                 ll_lambda=None, ll_weight_penalty=False, num_threads=None,\n",
    "                                 estimate_variance=False):\n",
    "\n",
    "    rf = forest_obj[\"forest\"]\n",
    "    X_orig = newdata\n",
    "\n",
    "    if newdata is not None:\n",
    "        predictions = rf.predict(newdata)\n",
    "    else:\n",
    "        # Implement out-of-bag prediction logic if needed\n",
    "        predictions = rf.oob_prediction_\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Example usage:\n",
    "n = 50\n",
    "p = 10\n",
    "X = np.random.randn(n, p)\n",
    "Y = X[:, 0] * np.random.randn(n)\n",
    "\n",
    "forest_obj = ll_regression_forest(X, Y)\n",
    "predictions = predict_ll_regression_forest(forest_obj, X)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
